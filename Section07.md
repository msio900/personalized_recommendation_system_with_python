# ğŸ‘Section 07_ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì‹œìŠ¤í…œ[â†©](../../)

## contentsğŸ“‘<a id='contents'></a>

* 0_ ë“¤ì–´ê°€ê¸° ì „ì—[âœï¸](#0)
* 1_ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì‹œìŠ¤í…œì˜ ì¥ì 
* 2_ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì‹œìŠ¤í…œì˜ ì›ë¦¬
* 3_ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì‹œìŠ¤í…œ(CFì™€ MFì˜ ê²°í•©)

## 0_ ë“¤ì–´ê°€ê¸° ì „ì—[ğŸ“‘](#contents)<a id='0'></a>

![](./image/7_0-1.png)

## 1_ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì‹œìŠ¤í…œì˜ ì¥ì [ğŸ“‘](#contents)<a id='1'></a>

![](./image/7_1-1.png)

## 2_ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì‹œìŠ¤í…œì˜ ì›ë¦¬[ğŸ“‘](#contents)<a id='2'></a>

```python
from sklearn.model_selection import train_test_split
import random
import numpy as np
import pandas as pd

r_cols = ["user_id","movie_id",'rating','timestamp']
ratings = pd.read_csv('./Data/u.data',
                    sep = '\t',
                    names = r_cols,
                    encoding='latin-1')

ratings_train, ratings_test = train_test_split(ratings, 
                                               test_size = 0.2,
                                               shuffle = True,
                                               random_state = 2021)

def RMSE2(y_true, y_pred):
  return np.sqrt(np.mean((np.array(y_true)-np.array(y_pred))**2))

#2ê°œì˜ ë”ë¯¸ ì¶”ì²œ ì—”ì§„ 
def recommender_1(recom_list):      #ì¶”ì²œí•´ì•¼í•  ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ì˜¤ê³  
  recommendations = [] #ì˜ˆì¸¡ì¹˜ ì €ì¥ 
  for pair in recom_list: 
    recommendations.append(random.random() * 4 + 1) # 1~5ì‚¬ì´ì˜ ë‚œìˆ˜ ë°œìƒ 
  return np.array(recommendations)

def recommender_2(recom_list): 
  recommendations = [] #ì˜ˆì¸¡ì¹˜ ì €ì¥ 
  for pair in recom_list: 
    recommendations.append(random.random() * 4 + 1) #1~5ì‚¬ì´ì˜ ë‚œìˆ˜ ë°œìƒ 
  return np.array(recommendations)

weight = [0.8, 0.2] #ê²°í•© ë¹„ì¤‘ 
recom_list = np.array(ratings_test)
predictions_1 = recommender_1(recom_list)
predictions_2 = recommender_2(recom_list)

predictions = predictions_1 * weight[0] + predictions_2 * weight[1] # ë‘ ì¶”ì²œì—”ì§„ì˜ ì˜ˆì¸¡ê°’ì„ ê°€ì¤‘ì¹˜ ì²˜ë¦¬í•¨.
RMSE2(recom_list[:,2], predictions)

# ì‹¤í–‰ ê²°ê³¼
1.5707050630820683
```

## 3_ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì‹œìŠ¤í…œ(CFì™€ MFì˜ ê²°í•©)[ğŸ“‘](#contents)<a id='3'></a>

* ì‹¤ì œ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì‹œìŠ¤í…œ êµ¬í˜„

  ```python
  from sklearn.model_selection import train_test_split
  import random
  import numpy as np
  import pandas as pd
  import os 
  
  #MFë°©ì‹ 
  class NEW_MF(): 
    def __init__(self, ratings, hyper_params): 
      self.R = np.array(ratings)
      #ì‚¬ìš©ì ìˆ˜(num_users)ì™€ ì•„ì´í…œ ìˆ˜(num_iterms)ë¥¼ ë°›ì•„ì˜¨ë‹¤.
      self.num_users, self.num_items = np.shape(self.R)
      #ì•„ë˜ëŠ” MF weight ì¡°ì ˆì„ ìœ„í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì´ë‹¤. 
      #K : ì ì¬ìš”ì¸ì˜ ìˆ˜ 
      self.K = hyper_params['K'] #keyê°’ 
      self.alpha = hyper_params['alpha'] #í•™ìŠµë¥ 
      self.beta = hyper_params['beta'] #ì •ê·œí™” ê³„ìˆ˜ 
      self.iterations = hyper_params['iterations'] #ë°˜ë³µ íšŸìˆ˜
      self.verbose = hyper_params['verbose'] #í•™ìŠµê³¼ì • ì¶œë ¥ ì—¬ë¶€ ê²°ì • 
    
      # ë§¤í•‘ : indexë¥¼ ë§ì¶°ì¤Œ 
      # item id 
      item_id_index = []
      index_item_id = []
      for i, one_id in enumerate(ratings): #i : index, one_id : movie_id
        item_id_index.append([one_id, i])
        index_item_id.append([i, one_id])
      self.item_id_index = dict(item_id_index)
      self.index_item_id = dict(index_item_id)
      
      #user id 
      user_id_index = []
      index_user_id  = []
      for i, one_id in enumerate(ratings.T): #i : index, one_id : user_id
        user_id_index.append([one_id, i])    
        index_user_id.append([i, one_id])
      self.user_id_index = dict(user_id_index)
      self.index_user_id = dict(index_user_id)
    
    def rmse(self):
      #rating dataì—ì„œ 0ì´ ì•„ë‹Œ ìš”ì†Œì˜ ì¸ë±ìŠ¤
      xs, ys = self.R.nonzero() 
      #predictionê³¼ errorë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸ ë³€ìˆ˜ ì´ˆê¸°í™” 
      self.predictions = []
      self.errors = [] 
      #í‰ì ì´ ìˆëŠ” ìš”ì†Œ(ì‚¬ìš©ì x, ì•„ì´í…œ y) ê°ê°ì— ëŒ€í•´ì„œ ì•„ë˜ì˜ ì½”ë“œë¥¼ ì‹¤í–‰í•œë‹¤. 
      for x,y in zip(xs, ys): 
        #ì‚¬ìš©ì x, ì•„ì´í…œ yì— ëŒ€í•´ì„œ í‰ì  ì˜ˆì¸¡ì¹˜ë¥¼ get_predition() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ì„œ ê³„ì‚°í•œë‹¤.
        prediction = self.get_prediction(x,y)
        #ì˜ˆì¸¡ê°’ì„ ì˜ˆì¸¡ê°’ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•œë‹¤.
        self.predictions.append(prediction)
        #ì‹¤ì œê°’(R)ê³¼ ì˜ˆì¸¡ê°’ì˜ ì°¨ì´(errors) ê³„ì‚°í•´ì„œ ì˜¤ì°¨ê°’ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•œë‹¤.
        self.errors.append(self.R[x,y]-prediction)
      #ì˜ˆì¸¡ê°’ ë¦¬ìŠ¤íŠ¸ì™€ ì˜¤ì°¨ê°’ ë¦¬ìŠ¤íŠ¸ë¥¼ numpy arrayí˜•íƒœë¡œ ë³€í™˜í•œë‹¤.
      self.predictions = np.array(self.predictions)
      #errorë¥¼ í™œìš©í•´ì„œ RMSE ë„ì¶œ 
      self.errors = np.array(self.errors)
      return np.sqrt(np.mean(self.errors**2))
  
    def sgd(self): 
      for i,j,r in self.samples:  #i,j : ì¸ë±ìŠ¤, r : í‰ì  
        #ì‚¬ìš©ì i, ì•„ì´í…œ jì— ëŒ€í•œ í‰ì  ì˜ˆì¸¡ì¹˜ ê³„ì‚° 
        prediction = self.get_prediction(i,j)
        #ì‹¤ì œ í‰ì ê³¼ ë¹„êµí•œ ì˜¤ì°¨ ê³„ì‚° 
        e = (r-prediction)
        # ê°€ì¤‘ì¹˜ì— ëŒ€í•´ì„œ ê³„ì†í•´ì„œ ì—…ë°ì´íŠ¸ í•¨. í¸ë¯¸ë¶„
        #ì‚¬ìš©ì í‰ê°€ ê²½í–¥ ê³„ì‚° ë° ì—…ë°ì´íŠ¸
        self.b_u[i] += self.alpha * (e - (self.beta * self.b_u[i]))
        #ì•„ì´í…œ í‰ê°€ ê²½í–¥ ê³„ì‚° ë° ì—…ë°ì´íŠ¸
        self.b_d[j] += self.alpha * (e- (self.beta * self.b_d[j]))
  
        #P í–‰ë ¬ ê³„ì‚° ë° ì—…ë°ì´íŠ¸
        self.P[i,:] += self.alpha * ((e * self.Q[j,:] - self.beta * self.P[i,:]))
        #Q í–‰ë ¬ ê³„ì‚° ë° ì—…ë°ì´íŠ¸
        self.Q[j,:] += self.alpha * ((e * self.P[i,:])- (self.beta * self.Q[j, :]))
  
    def get_prediction(self, i, j): 
      #ì‚¬ìš©ì i, ì•„ì´í…œ jì— ëŒ€í•œ í‰ì  ì˜ˆì¸¡ì¹˜ë¥¼ ì•ì—ì„œ ë°°ì› ë˜ ì‹ì„ ì´ìš©í•´ì„œ êµ¬í•œë‹¤.
      prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i,:].dot(self.Q[j,].T) #ì „ì²´ í‰ì  + ìœ ì €ì— ëŒ€í•œ í‰ê°€ ê²½í•­ + ì•„ì´í…œì— ëŒ€í•œ í‰ê°€ ê²½í–¥ + ì‚¬ìš©ì ìš”ì¸ê°’*ì•„ì´í…œ ìš”ì¸ê°’
      return prediction 
  
    #Test set ì„ ì • 
    def set_test(self, ratings_test):
      test_set = []
      for i in range(len(ratings_test)):
        x = self.user_id_index[ratings_test.iloc[i,0]] #user index
        y = self.item_id_index[ratings_test.iloc[i,1]] #item index
        z = ratings_test.iloc[i,2] #ì‹¤ì œ í‰ì  
        test_set.append([x,y,z])
        self.R[x,y] = 0 #í‰ì  0ìœ¼ë¡œ ë§Œë“¤ê¸° 
      self.test_set = test_set 
      return test_set 
  
    #Test set RMSE ê³„ì‚° 
    def test_rmse(self):
      error = 0
      for one_set in self.test_set: 
        predicted = self.get_prediction(one_set[0],one_set[1])
        #pow : ì°¨ìŠ¹ 
        error += pow(one_set[2]-predicted, 2)
      return np.sqrt(error/len(self.test_set))
  
    def test(self): #í•™ìŠµ 
      self.P = np.random.normal(scale=1./self.K,
                                size = (self.num_users, self.K))
      self.Q = np.random.normal(scale=1./self.K,
                                size = (self.num_items, self.K))
      self.b_u = np.zeros(self.num_users)
      self.b_d = np.zeros(self.num_items)
      self.b = np.mean(self.R[self.R.nonzero()])
  
      rows, columns = self.R.nonzero() 
      self.samples = [(i,j,self.R[i,j]) for i,j in zip(rows, columns)]
  
      training_process = []
      for i in range(self.iterations):
        np.random.shuffle(self.samples)
        self.sgd() #weight ê°’ ì—…ë°ì´íŠ¸ 
        rmse1 = self.rmse() #training set
        rmse2 = self.test_rmse() #test set
        training_process.append((i+1, rmse1, rmse2))
        if self.verbose == True:
          if (i+1) % 10 == 0:
            print("Iteration : %d ; train RMSE = %.4f; test RMSE %.4f"%(i+1, rmse1, rmse2))
      return training_process 
  
    def get_one_prediction(self, user_id, item_id): #í•˜ë‚˜ ì˜ˆì¸¡ 
      return self.get_prediction(self.user_id_index[user_id],
                                 self.item_id_index[item_id])
    
    def full_prediction(self): #ì „ì²´ ì˜ˆì¸¡ 
      return self.b + self.b_u[:, np.newaxis] + self.b_d[np.newaxis, :] + self.P.dot(self.Q.T)
  
  base_src = './Data'
  u_data_src = os.path.join(base_src,'u.data')
  r_cols = ["user_id","movie_id",'rating','timestamp']
  ratings = pd.read_csv(u_data_src,
                      sep = '\t',
                      names = r_cols,
                      encoding='latin-1')
  
  ratings_train, ratings_test = train_test_split(ratings, 
                                                 test_size = 0.2,
                                                 shuffle = True,
                                                 random_state = 2021)
  
  #full matrix
  R_temp = ratings.pivot(index = 'user_id',
                         columns = 'movie_id',
                         values = 'rating').fillna(0)
        
  hyper_params = {
      'K' : 30,
      'alpha':0.001,
      'beta':0.02,
      'iterations':100,
      'verbose':True
  }
  
  mf = NEW_MF(R_temp, hyper_params)
  test_set = mf.set_test(ratings_test) #ì¼ë¶€ë¶„ì€ testë¡œ ì§€ì • 
  result = mf.test()
  
  
  
  ###################################################################
  
  from sklearn.metrics.pairwise import cosine_similarity
  
  rating_matrix = ratings_train.pivot(index ="user_id", columns = "movie_id", values = "rating")
  
  rating_mean = rating_matrix.mean(axis=1) 
  rating_bias = (rating_matrix.T - rating_mean).T #ì‚¬ìš©ì í‰ê°€ ê²½í–¥ ê³ ë ¤
  
  matrix_dummy = rating_matrix.copy().fillna(0)
  user_similarity = cosine_similarity(matrix_dummy, matrix_dummy)
  user_similarity = pd.DataFrame(user_similarity,
                                 index = rating_matrix.index,
                                 columns = rating_matrix.index)
  
  #CF ë°©ì‹ 
  def CF_knn_bias(user_id, movie_id, neighbor_size=0):
    if movie_id in rating_bias.columns: 
      sim_scores = user_similarity[user_id].copy()
      movie_ratings = rating_bias[movie_id].copy()
      none_rating_idx = movie_ratings[movie_ratings.isnull()].index
      movie_ratings = movie_ratings.drop(none_rating_idx)
      sim_scores = sim_scores.drop(none_rating_idx)
  
      if neighbor_size == 0:
        prediction = np.dot(sim_scores, movie_ratings) / sim_scores.sum()
        prediction = prediction + rating_mean[user_id]
  
      else:
        if len(sim_scores) > 1:
          neighbor_size = min(neighbor_size, len(sim_scores))
          sim_scores = np.array(sim_scores)
          movie_ratings = np.array(movie_ratings)
          user_idx = np.argsort(sim_scores)
          sim_scores = sim_scores[user_idx][-neighbor_size:]
          movie_ratings = movie_ratings[user_idx][-neighbor_size:]
          prediction = np.dot(sim_scores, movie_ratings) / sim_scores.sum()
          prediction = prediction + rating_mean[user_id]
        else: 
          prediction = rating_mean[user_id] #ì‚¬ìš©ìì˜ í‰ê°€ê²½í–¥ ê³ ë ¤ 
    else: 
      prediction = rating_mean[user_id]
    return prediction
  
  
  def RMSE2(y_true, y_pred):
    return np.sqrt(np.mean((np.array(y_true)-np.array(y_pred))**2))
  
  #Hybrid ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ 
  def recommender_1(recom_list, mf):
    recommendations = np.array([
                                mf.get_one_prediction(user, movie) for (user, movie) in recom_list
    ])
    return recommendations
  
  def recommender_2(recom_list, neighbor_size=0):
    recommendations = np.array([
                                CF_knn_bias(user, movie, neighbor_size) for (user, movie) in recom_list
    ])
    return recommendations
  
  
  recom_list = np.array(ratings_test.iloc[:,[0,1]]) #ì „ì²´ì—ì„œ user_id, movie_id
  predictions_1 = recommender_1(recom_list, mf)
  predictions_2 = recommender_2(recom_list, 37)
  
  print('reco 1 :', RMSE2(ratings_test.iloc[:,2], predictions_1))
  print('reco 2 :', RMSE2(ratings_test.iloc[:,2], predictions_2))
  
  
  weight = [0.8, 0.2]
  predictions = predictions_1 * weight[0] + predictions_2 * weight[1]
  
  print('reco 1+2 : ', RMSE2(ratings_test.iloc[:,2], predictions))
  ```

* ìµœì ì˜ ì˜ˆì¸¡ ëª¨ë¸ ì°¾ê¸°

  ```python
  result = []
  weight_rate = []
  for i in np.arange(0.1, 0.01):
      weight = [i, 1.0-i]
      predictions = predictions_1 * weight[0] + predictions_2 * weight[1]
      print("weight - %.2f RMSE = %.7f"%(weight[0], weight[1], RMSE2(ratings_test.iloc[:,2], predictions)))
      result.append(RMSE2(ratings_test.iloc[:,2], predictions))
      weight_rate.append(weight)
  print(min(result))
  index_min = result.index(min(result))
  print(weight_rate[index_min])
  ```

  
