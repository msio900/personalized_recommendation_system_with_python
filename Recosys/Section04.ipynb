{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 SGD를 사용한 MF 기본 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "base_src =  './Data'\n",
    "u_data_src = os.path.join(base_src, 'u.data')\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv(u_data_src,\n",
    "                        sep='\\t',\n",
    "                        names=r_cols,\n",
    "                        encoding='latin-1')\n",
    "\n",
    "# timestamp 제거\n",
    "ratings = ratings[['user_id', 'movie_id', 'rating']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 10 ; train RMSE = 0.9588\n",
      "Iteration : 20 ; train RMSE = 0.9380\n",
      "Iteration : 30 ; train RMSE = 0.9291\n",
      "Iteration : 40 ; train RMSE = 0.9241\n",
      "Iteration : 50 ; train RMSE = 0.9208\n",
      "Iteration : 60 ; train RMSE = 0.9185\n",
      "Iteration : 70 ; train RMSE = 0.9166\n",
      "Iteration : 80 ; train RMSE = 0.9150\n",
      "Iteration : 90 ; train RMSE = 0.9135\n",
      "Iteration : 100 ; train RMSE = 0.9120\n"
     ]
    }
   ],
   "source": [
    "class MF():\n",
    "    def __init__(self, ratings, hyper_params):\n",
    "        self.R = np.array(ratings)\n",
    "        self.num_users, self.num_items = np.shape(self.R)\n",
    "        self.K = hyper_params['K']\n",
    "        self.alpha = hyper_params['alpha']\n",
    "        self.beta = hyper_params['beta']\n",
    "        self.iterations = hyper_params['iterations']\n",
    "        self.verbose = hyper_params['verbose']\n",
    "\n",
    "    def rmse(self):\n",
    "        xs, ys = self.R.nonzero()\n",
    "        self.predictions = []\n",
    "        self.errors = []\n",
    "\n",
    "        for x, y in zip(xs, ys):\n",
    "            prediction = self.get_prediction(x, y)\n",
    "            self.predictions.append(prediction)\n",
    "            self.errors.append(self.R[x, y] - prediction)\n",
    "        self.predictions = np.array(self.predictions)\n",
    "        self.errors = np.array(self.errors)\n",
    "\n",
    "        return np.sqrt(np.mean(self.errors**2))\n",
    "\n",
    "    def train(self):\n",
    "        self.P = np.random.normal(scale=1./self.K,                  # scale = 표준편차를 이야기함\n",
    "                                    size=(self.num_users, self.K))  # size 실제 유저수와 잠재요인의 갯수 = 크기 값\n",
    "        self.Q = np.random.normal(scale=1./self.K,\n",
    "                                    size = (self.num_items, self.K))\n",
    "\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_d = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[self.R.nonzero()])\n",
    "\n",
    "        rows, columns = self.R.nonzero()\n",
    "        self.samples = [(i, j, self.R[i, j]) for i, j in zip(rows, columns)]\n",
    "\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse = self.rmse()\n",
    "            training_process.append((i+1, rmse)) # 몇번 째의 RMSE인지?\n",
    "            if self.verbose:\n",
    "                if (i+1) % 10 == 0:\n",
    "                    print('Iteration : %d ; train RMSE = %.4f'%(i + 1, rmse))\n",
    "        return training_process\n",
    "\n",
    "    def get_prediction(self, i, j):\n",
    "        prediction = self.b + self.b_u[i] +self.b_d[j] + self.P[i, :].dot(self.Q[j,].T)\n",
    "        return prediction\n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_prediction(i, j)\n",
    "            e = (r-prediction)\n",
    "\n",
    "            self.b_u[i] += self.alpha * (e - (self.beta * self.b_u[i]))\n",
    "            self.b_d[j] += self.alpha * (e - (self.beta * self.b_d[j]))\n",
    "\n",
    "            self.P[i,:] += self.alpha * ((e * self.Q[j,:] - (self.beta * self.P[i, :])))\n",
    "            self.Q[j,:] += self.alpha * ((e * self.Q[i,:] - (self.beta * self.Q[j, :])))\n",
    "\n",
    "R_temp = ratings.pivot(index='user_id',\\\n",
    "                        columns='movie_id',\n",
    "                        values='rating').fillna(0)\n",
    "\n",
    "hyper_params = {\n",
    "    'K' : 30,\n",
    "    'alpha' : 0.001,\n",
    "    'beta' : 0.02,\n",
    "    'iterations' :100,\n",
    "    'verbose' : True\n",
    "}\n",
    "\n",
    "mf = MF(R_temp, hyper_params)\n",
    "\n",
    "train_process = mf.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 train/test 분리 MF 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; Train RMSE = 0.9666 ; Test RMSE = 0.9807\n",
      "Iteration: 20 ; Train RMSE = 0.9412 ; Test RMSE = 0.9623\n",
      "Iteration: 30 ; Train RMSE = 0.9297 ; Test RMSE = 0.9552\n",
      "Iteration: 40 ; Train RMSE = 0.9228 ; Test RMSE = 0.9515\n",
      "Iteration: 50 ; Train RMSE = 0.9179 ; Test RMSE = 0.9493\n",
      "Iteration: 60 ; Train RMSE = 0.9139 ; Test RMSE = 0.9478\n",
      "Iteration: 70 ; Train RMSE = 0.9101 ; Test RMSE = 0.9466\n",
      "Iteration: 80 ; Train RMSE = 0.9059 ; Test RMSE = 0.9455\n",
      "Iteration: 90 ; Train RMSE = 0.9008 ; Test RMSE = 0.9442\n",
      "Iteration: 100 ; Train RMSE = 0.8941 ; Test RMSE = 0.9425\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "base_src =  './Data'\n",
    "u_data_src = os.path.join(base_src, 'u.data')\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv(u_data_src,\n",
    "                        sep='\\t',\n",
    "                        names=r_cols,\n",
    "                        encoding='latin-1')\n",
    "\n",
    "# timestamp 제거\n",
    "ratings = ratings[['user_id', 'movie_id', 'rating']].astype(int)\n",
    "\n",
    "# train / test set 분리\n",
    "from sklearn.utils import shuffle\n",
    "TRAIN_SIZE = 0.75\n",
    "\n",
    "# (사용자 - 영화 - 평점)\n",
    "ratings = shuffle(ratings, random_state=2021)   # 모든 사람이 똑같은 raitings가 나오게 됨. \n",
    "cutoff = int(TRAIN_SIZE * len(ratings))\n",
    "ratings_train = ratings.iloc[:cutoff]           # 어디까지 \n",
    "ratings_test = ratings.iloc[cutoff:]            # 어디 이후로 데이터를 뽑으면 될것 인지?\n",
    "\n",
    "class NEW_MF():\n",
    "    def __init__(self, ratings, hyper_params):\n",
    "        self.R = np.array(ratings)\n",
    "        # 사용자 수 (num_users)와 아이템 수 (num_items)를 받아온다.\n",
    "        self.num_users, self.num_items = np.shape(self.R)\n",
    "        # 아래는 MF weight 조절을 위한 하이퍼 파라미더다.\n",
    "        # K : 잠재요인(latent factor)의 수\n",
    "        self.K = hyper_params['K']\n",
    "        # alpha : 학습률\n",
    "        self.alpha = hyper_params['alpha']\n",
    "        # beta : 정규화 개수\n",
    "        self.beta = hyper_params['beta']\n",
    "        # iterations : SGD의 계산을 할 때 반복 횟수\n",
    "        self.iterations = hyper_params['iterations']\n",
    "        # verbose : SGD의 학습 과정을 중간중간에 출력할 것인지에 대한 여부\n",
    "        self.verbose = hyper_params['verbose']\n",
    "\n",
    "        # 지난 시간과 조금 다른 부분\n",
    "        # movie_lens 데이터는 굉장히 잘 정리된 데이터 이지만, 현업의 데이터는 연속값이 아닐 수 있음. \n",
    "        # self.R을 numpy로 변환 시킬 경우 중간에 비어있는 실제 id 랑 self.R의 값과 매칭이 안됨.\n",
    "        ### Item id에 관한 ###\n",
    "        item_id_index = []\n",
    "        index_item_id = []\n",
    "        for i, one_id in enumerate(ratings):\n",
    "            item_id_index.append([one_id, i])\n",
    "            index_item_id.append([i, one_id])\n",
    "        self.item_id_index = dict(item_id_index)    # 어떤 id 값이 들어오더라도 id 값과 numpy array와 매핑 시켜줌.\n",
    "        self.index_item_id = dict(index_item_id)\n",
    "\n",
    "        user_id_index = []\n",
    "        index_user_id = []\n",
    "        for i, one_id in enumerate(ratings.T):\n",
    "            user_id_index.append([one_id, i])\n",
    "            index_user_id.append([i, one_id])\n",
    "        self.user_id_index = dict(user_id_index)\n",
    "        self.index_user_id = dict(index_user_id)\n",
    "\n",
    "\n",
    "    def rmse(self):\n",
    "        # self.R에서 평점이 있는 (0이 아닌) 요소의 인덱스를 가져온다.\n",
    "        xs, ys = self.R.nonzero()\n",
    "        # prediction과 error를 담을 리스트 변수 초기화\n",
    "        self.predictions = []\n",
    "        self.errors = []\n",
    "        # 평점이 있는 요소(사용자 x, 아이템 y) 각각에 대해서 아래의 코드를 실행한다.\n",
    "        for x, y in zip(xs, ys):\n",
    "            # 사용자 x, 아이템 y에 대해서 평점 예측치를 get_prediction()함수를 사용해서 계산한다.\n",
    "            prediction = self.get_prediction(x, y)\n",
    "            # 예측값을 예측값 리스트에 추가한다.\n",
    "            self.predictions.append(prediction)\n",
    "            # 실제값(R)과 예측값의 차이(errors) 계산해서 오차값 리스트에 추가한다.\n",
    "            self.errors.append(self.R[x, y] - prediction)\n",
    "        # 예측값 리스트와 오차값 리스트를 numpy array형태로 변환한다.\n",
    "        self.predictions = np.array(self.predictions)\n",
    "        self.errors = np.array(self.errors)\n",
    "        # error를 활용해서 RMSE를 도출\n",
    "        return np.sqrt(np.mean(self.errors**2))\n",
    "\n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            # 사용자 i : 아이템 j에 대한 평점 예측치 계산\n",
    "            prediction = self.get_prediction(i, j)\n",
    "            # 실제 평점과 비교한 오차 계산\n",
    "            e = (r - prediction)\n",
    "            # 사용자 평가 경향 계산 및 업데이트\n",
    "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
    "            # 아이템 평가 경향 계산 및 업데이트\n",
    "            self.b_d[j] += self.alpha * (e - self.beta * self.b_d[j])\n",
    "            # P 행렬 계산 및 업데이트\n",
    "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])\n",
    "            # Q 행렬 계산 및 업데이트\n",
    "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])\n",
    "    def get_prediction(self, i, j):\n",
    "        # 사용자 i, 아이템 j에 대한 평점 예측치를 앞에서 배웠던 식을 이용해서 구한다.\n",
    "        prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        return prediction\n",
    "\n",
    "    # Test set 선정\n",
    "    def set_test(self, ratings_test):\n",
    "        test_set = []\n",
    "        for i in range(len(ratings_test)):      # test 데이터에 있는 각 데이터에 대해서\n",
    "            x = self.user_id_index[ratings_test.iloc[i, 0]]\n",
    "            y = self.item_id_index[ratings_test.iloc[i, 1]]\n",
    "            z = ratings_test.iloc[i, 2]\n",
    "            test_set.append([x, y, z])\n",
    "            self.R[x, y] = 0                    # test set으로 지정한 것들은 모두 0으로\n",
    "        self.test_set = test_set\n",
    "        return test_set                   \n",
    "\n",
    "\n",
    "    # Test set RMSE 계산\n",
    "    def test_rmse(self):\n",
    "        error = 0   # 0으로 초기화\n",
    "        for one_set in self.test_set:\n",
    "            predicted = self.get_prediction(one_set[0], one_set[1])\n",
    "            error += pow(one_set[2] - predicted, 2)         # pow : e => e^2 차승\n",
    "        return np.sqrt(error/len(self.test_set))\n",
    "\n",
    "    def test(self):\n",
    "        # Initializing user-feature and item-feature matrix\n",
    "        self.P = np.random.normal(scale=1./self.K,\n",
    "                                    size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, \n",
    "                                    size=(self.num_items, self.K))\n",
    "\n",
    "        # 유저 경향\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_d = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[self.R.nonzero()]) # 온전히 걸린것들만 계산하게 함. \n",
    "\n",
    "        # List of training samples\n",
    "        rows, columns = self.R.nonzero()            # non zero인 것만 인덱스를 가져옴.\n",
    "        self.samples = [(i, j, self.R[i,j]) for i, j in zip(rows, columns)]\n",
    "\n",
    "        # Stochastic gradient descent for given number of iterations\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse1 = self.rmse()\n",
    "            rmse2 = self.test_rmse()\n",
    "            training_process.append((i+1, rmse1, rmse2))\n",
    "            if self.verbose:\n",
    "                if (i+1) % 10 == 0:\n",
    "                    print(\"Iteration: %d ; Train RMSE = %.4f ; Test RMSE = %.4f\" % (i+1, rmse1, rmse2))\n",
    "        return training_process\n",
    "\n",
    "    def get_one_prediction(self, user_id, item_id):\n",
    "        return self.get_prediction(self.user_id_index[user_id],\n",
    "                                    self.item_id_index[item_id])    # 예측치를 계산해줌.\n",
    "    \n",
    "    # Full user-movie rating matrix\n",
    "    def full_prediction(self):\n",
    "        return self.b + self.b_u[:,np.newaxis] + self.b_d[np.newaxis,:] + self.P.dot(self.Q.T) # 전체를 계산해줌.\n",
    "\n",
    "R_temp = ratings.pivot(index='user_id',\n",
    "                    columns = 'movie_id',\n",
    "                    values = 'rating').fillna(0)\n",
    "\n",
    "hyper_params = {\n",
    "    'K' : 30,\n",
    "    'alpha' : 0.001,\n",
    "    'beta' : 0.02,\n",
    "    'iterations' : 100,\n",
    "    'verbose' : True\n",
    "}\n",
    "\n",
    "mf = NEW_MF(R_temp, hyper_params)\n",
    "\n",
    "test_set = mf.set_test(ratings_test)\n",
    "results = mf.test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.91454543 3.39333233 2.98759373 ... 3.38110623 3.46510384 3.41074121]\n",
      " [3.80528174 3.24899288 2.90001427 ... 3.26739582 3.36065561 3.33977482]\n",
      " [3.40858422 2.91780662 2.49550962 ... 2.88229575 2.9774935  2.94997816]\n",
      " ...\n",
      " [4.14704511 3.60480179 3.24708529 ... 3.58197039 3.70818832 3.69413186]\n",
      " [4.32293351 3.78026638 3.40714565 ... 3.75817252 3.89115358 3.86689988]\n",
      " [3.83928592 3.36202847 2.94700558 ... 3.29387556 3.42047262 3.39708125]]\n"
     ]
    }
   ],
   "source": [
    "print(mf.full_prediction())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3933323287310477\n"
     ]
    }
   ],
   "source": [
    "print(mf.get_one_prediction(1, 2))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c65b98e956c6ae24f8ae0bc56d1e465ff92310dbdec0a4bd6b48ffdf1441c98"
  },
  "kernelspec": {
   "display_name": "Python 3.6.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
